{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"CompanyName1\": \"Modaxo (Constellation Software, Canada)\",\n",
      "    \"JobTitle\": \"Full stack Developer\",\n",
      "    \"JobPeriod\": \"06/2021 - 04/2024\"\n",
      "},\n",
      "{\n",
      "    \"CompanyName2\": \"Virtusa (CIBC - Capital Market, Canada)\",\n",
      "    \"JobTitle\": \"Senior Application Developer\",\n",
      "    \"JobPeriod\": \"02/2020 - 06/2021\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.chat_engine import ContextChatEngine\n",
    "from llama_index_client import ChatMessage, MessageRole\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "Settings.node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=20)\n",
    "Settings.num_output = 512\n",
    "Settings.context_window = 3900\n",
    "\n",
    "# create index with Documents + LLM\n",
    "index2 = VectorStoreIndex.from_documents(\n",
    "    documents, embed_model=Settings.embed_model, llm=Settings.llm\n",
    ")\n",
    "\n",
    "chatRetreiver = index2.as_retriever()\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=5500)\n",
    "\n",
    "messageHistory =  [ \n",
    "                    ChatMessage(\n",
    "                        role=MessageRole.SYSTEM,\n",
    "                        content=\n",
    "                                \"You are an expert assitant for extracting insights from resume in PDF format. \\n\"\n",
    "                                \"You extract data and return it in JSON format, as below \\n\"\n",
    "                                \"  {\\n\"\n",
    "                                \"    CompanyName1:\\n\"\n",
    "                                \"    JobTitle:\\n\"\n",
    "                                \"    JobPeriod:\\n\"\n",
    "                                \"  }\\n\"\n",
    "                                \"REMEMBER to return extracted data only from provided resume.\",\n",
    "                        additional_kwargs={\"2\":\"2\"}\n",
    "                        ),\n",
    "                    ChatMessage(\n",
    "                        role=MessageRole.USER,\n",
    "                        content=\"Hello assistant, we are having a insightful discussion about Ramya Anand today.\",\n",
    "                        additional_kwargs={\"2\":\"2\"}\n",
    "                        ),\n",
    "                    ChatMessage(\n",
    "                        role=MessageRole.ASSISTANT, \n",
    "                        content=\"Okay, sounds good.\",\n",
    "                        additional_kwargs={\"2\":\"2\"}\n",
    "                        ),\n",
    "                  ]\n",
    "\n",
    "newMessage = \"List the companies Ramya Anand has worked, her role, job period in Json format?\"\n",
    "\n",
    "chatEngine = ContextChatEngine(chatRetreiver, Settings.llm, memory= memory, prefix_messages= messageHistory)\n",
    "response3 = chatEngine.chat(newMessage)\n",
    "print(response3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"CompanyName3\": \"Bank of NewYork Mellon, US / India\",\n",
      "    \"JobTitle\": \"Lead - Application Development\",\n",
      "    \"JobPeriod\": \"07/2017 - 12/2019\"\n",
      "  },\n",
      "  {\n",
      "    \"CompanyName4\": \"iNautix Technologies, US / India\",\n",
      "    \"JobTitle\": \"Technical Lead\",\n",
      "    \"JobPeriod\": \"07/2014 - 06/2017\"\n",
      "  },\n",
      "  {\n",
      "    \"CompanyName5\": \"iNautix Technologies, US / India\",\n",
      "    \"JobTitle\": \"Senior Application Developer\",\n",
      "    \"JobPeriod\": \"04/2012 - 06/2014\"\n",
      "  },\n",
      "  {\n",
      "    \"CompanyName6\": \"iNautix Technologies, US / India\",\n",
      "    \"JobTitle\": \"Application Developer\",\n",
      "    \"JobPeriod\": \"07/2009 - 03/2012\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response4 = chatEngine.chat(\"What are the other companies she worked for apart from the ones listed already? \\n\"\n",
    "                            \"Return the response in same Json format, continue with the company serial numbers\")\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import relativedelta\n",
    "from pydantic import Field\n",
    "\n",
    "def caculateTimePeriod(fromDateString: str, toDateString: str, dateFormat: str = '%m/%Y'):\n",
    "    # calulate time period between two dates in the given date format like '%m/%Y'\n",
    "    fromDate = datetime.strptime(fromDateString, dateFormat)\n",
    "    toDate = datetime.strptime(toDateString, dateFormat)\n",
    "    delta = relativedelta.relativedelta(toDate, fromDate)\n",
    "    duration = f\"{delta.years} Years and {delta.months} months\"\n",
    "    return duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 Years and 8 months'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caculateTimePeriod(\"07/2009\", \"03/2012\", \"%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "timePeriodFunctionTool = FunctionTool.from_defaults(caculateTimePeriod, name= \"caculateTimePeriod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "\n",
    "documents = SimpleDirectoryReader(\"Data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents, show_progress = True)\n",
    "\n",
    "queryEngineTool = QueryEngineTool.from_defaults(\n",
    "    index.as_query_engine(), name=\"ProfileQueryEngine\", description=\"reads profile information from bio data, resume, references so on\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: where Ramya worked in 2020?\n",
      "Return the response in Json format with Company name, role, job period information\n",
      "=== Calling Function ===\n",
      "Calling function: caculateTimePeriod with args: {\"fromDateString\":\"01/01/2020\",\"toDateString\":\"12/31/2020\"}\n",
      "Got output: Error: time data '01/01/2020' does not match format '%m/%Y'\n",
      "========================\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: caculateTimePeriod with args: {\"fromDateString\": \"01/01/2020\", \"toDateString\": \"12/31/2020\", \"dateFormat\": \"%m/%d/%Y\"}\n",
      "Got output: 0 Years and 11 months\n",
      "========================\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: ProfileQueryEngine with args: {\"input\": \"Ramya work history in 2020\"}\n",
      "Got output: Ramya worked as a Senior Application Developer at Virtusa (CIBC - Capital Market, Canada) from February 2020 to June 2021.\n",
      "========================\n",
      "\n",
      "{\n",
      "  \"Company\": \"Virtusa (CIBC - Capital Market, Canada)\",\n",
      "  \"Role\": \"Senior Application Developer\",\n",
      "  \"JobPeriod\": \"February 2020 to June 2021\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "agent = OpenAIAgent.from_tools([queryEngineTool, timePeriodFunctionTool], verbose=True)\n",
    "\n",
    "responseFromTool = agent.chat(\"Where Ramya worked in 2020?\\n\"\n",
    "                              \"Return the response in Json format with Company name, role, job period information\")\n",
    "\n",
    "print(responseFromTool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Calcluate time period in this job\n",
      "=== Calling Function ===\n",
      "Calling function: caculateTimePeriod with args: {\"fromDateString\":\"02/2020\",\"toDateString\":\"06/2021\",\"dateFormat\":\"%m/%Y\"}\n",
      "Got output: 1 Years and 4 months\n",
      "========================\n",
      "\n",
      "Ramya worked as a Senior Application Developer at Virtusa (CIBC - Capital Market, Canada) for 1 year and 4 months from February 2020 to June 2021.\n"
     ]
    }
   ],
   "source": [
    "responseFromTool1 = agent.chat(\"Calcluate time period in this job\")\n",
    "\n",
    "print(responseFromTool1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
